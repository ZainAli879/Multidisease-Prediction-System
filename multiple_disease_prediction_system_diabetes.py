# -*- coding: utf-8 -*-
"""Multiple_disease_prediction_system_diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iv0f3g7V6ojhVRvVcGCfCrdDk9E4fEhz

**Importing the Dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn import svm
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

from google.colab import drive
drive.mount('/content/drive')

"""# Data Collection

PIMA Diabetes Dataset
"""

# loading the diabetes dataset to a pandas DataFrame
diabetes_dataset = pd.read_csv('/content/drive/MyDrive/Multidisease_datasets/diabetes.csv')

# printing the first 5 rows of the dataset
diabetes_dataset.head()

"""# Data Exploration and Understanding"""

# number of rows and Columns in this dataset
diabetes_dataset.shape

#Frequency distribution of Outcome variable
#Number of instances(rows) that belong to each class
#Size() is used for displaying number of rows associated with each value of target variable
diabetes_dataset.groupby('Outcome').size()

#Display the count of unique values in Outcome
diabetes_dataset['Outcome'].value_counts()

# getting the statistical measures of the data
diabetes_dataset.describe()

diabetes_dataset['Outcome'].value_counts()

"""0 --> Non-Diabetic

1 --> Diabetic
"""

diabetes_dataset.groupby('Outcome').mean()

#Visualizing the frequency distribution
f, ax = plt.subplots(figsize=(8,6))
ax = sns.countplot(x="Outcome", data=diabetes_dataset)
plt.show

#Frequency distribution of target variable w.r.t different features
#Frequency distribution of target variable w.r.t pregnancies feature
#How many males and females are with diabetes and without diabetes
diabetes_dataset.groupby('Pregnancies')['Outcome'].value_counts()

#Visualizing count of the 'Pregnencies' variable w.r.t target
f, ax = plt.subplots(figsize=(8,6))
ax = sns.countplot(x="Pregnancies", hue="Outcome", data= diabetes_dataset)
plt.show()

"""# Findings of the univariate analysis"""

# getting the statistical measures of the data
diabetes_dataset.describe()

# getting information about features and their datatypes
diabetes_dataset.info()

#Analyzing the Outcome Variable
diabetes_dataset["Outcome"].describe()

"""#Bivariate Analysis"""

#Corelation between features and target
correlations = diabetes_dataset.corr()
print(correlations["Outcome"].sort_values(ascending=False)) # Assuming you want to sort in descending order

#Analysis of Glucose and target variable
diabetes_dataset['Glucose'].nunique()

#Visualize the frequency distribution
f, ax = plt.subplots(figsize=(100,10))
ax = sns.countplot(x="Glucose", data=diabetes_dataset)
plt.show()

#Frequency distribution of target vaiable w.r.t Glucose
diabetes_dataset.groupby('Glucose')['Outcome'].value_counts()

#Analysis of BMI and target variable
diabetes_dataset['BMI'].nunique()

#Visualize the frequency distribution
f, ax = plt.subplots(figsize=(118,10))
ax = sns.countplot(x="BMI", data=diabetes_dataset)
plt.show()

#Freuency distribution of BMI
diabetes_dataset['BMI'].value_counts()

#Frequency distribution of target vaiable w.r.t BMI
diabetes_dataset.groupby('BMI')['Outcome'].value_counts()

"""# Multivariate Analysis"""

# Multivariate Analysis are performed to discover patterns and relationsip in the dataset
# Compute correlation matrix
correlation_matrix = diabetes_dataset[["Pregnancies", "Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI", "DiabetesPedigreeFunction", "Age", "Outcome"]].corr()

# Create a heatmap with annotations
fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(correlation_matrix, cmap="coolwarm", annot=True, fmt=".2f", square=True)
plt.show()

#Analyzing individual features wrt target
y = diabetes_dataset["Outcome"]
sns.countplot(y)
plt.show()
outcome_values = diabetes_dataset.Outcome.value_counts()
print(outcome_values)

#Analysing the sex feature
diabetes_dataset["Age"].unique()

sns.histplot(diabetes_dataset["Age"])

diabetes_dataset["Insulin"].unique()

sns.histplot(diabetes_dataset["Insulin"])

#Analysing the Glucose feature
diabetes_dataset["Glucose"].unique()

sns.barplot(diabetes_dataset["Glucose"])

sns.histplot(diabetes_dataset["Glucose"])

"""# Data Cleaning"""

# Check for missing values
print(diabetes_dataset.isnull().sum())

"""Our dataset is already cleaned so we dont need to apply any technique to clean our data

# Data Preprocessing

# Separating the features

Separating data into features (X) and labels (Y) is necessary for training supervised machine learning models. Features are used as input for training the model, and labels represent the desired output. This division is fundamental for the model to learn relationships between inputs and outputs during training and make predictions on new data.
"""



# separating the data and labels
X = diabetes_dataset.drop(columns = 'Outcome', axis=1)
Y = diabetes_dataset['Outcome']

print(X)

print(Y)

"""# **Train Test Split**

The train-test split is a critical step in machine learning to evaluate the performance of a model. It involves dividing the dataset into training and testing sets.

Need:
It allows us to assess how well the model generalizes to new, unseen data. Without a separate test set, the model might perform well on the data it was trained on but poorly on new data (overfitting).

train_test_split is a function of model_selection(module of Sckit-learn library)
X and y: Features and labels, respectively, representing the dataset to be split.
test_size: Specifies the proportion of the dataset to include in the test split (e.g., test_size=0.2 for 20% testing).
random_state: Sets a seed for random number generation, ensuring reproducibility.
stratify: Maintains the distribution of classes in classification tasks during the split.
"""

X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#Lets Compare the shape of dataset noe after spliting it in testing and training data separately
print("Shape of X_Train:"+str(X_train.shape))
print("Shape of y_Train:"+str(y_train.shape))
print("Shape of X_Test:"+str(X_test.shape))
print("Shape of Y_Test:"+str(y_test.shape))

"""# Feature Selection

Perform Cross-Validation to Find the Best Alpha

Use GridSearchCV to find the optimal
ð›¼
Î± value:
"""

from sklearn.linear_model import Lasso
# Define the Lasso model
lasso = Lasso()

# Define the parameter grid
alpha_values = np.logspace(-5, 1, 100)  # Search over a range of alpha values
param_grid = {'alpha': alpha_values}

# Perform grid search with cross-validation
grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)
grid_search.fit(X_train_scaled, y_train)

# Get the best alpha value
best_alpha = grid_search.best_params_['alpha']
print(f"Best alpha value: {best_alpha}")

from sklearn.linear_model import Lasso

# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply Lasso regression
lasso = Lasso(alpha=0.004)  # Adjust alpha for regularization strength
lasso.fit(X_scaled, y)

# Get the coefficients
coefficients = lasso.coef_

# Select features with non-zero coefficients
features_kept = X.columns[coefficients != 0]
print("Features kept after Lasso regression:", features_kept)

"""# Remove redundant or irrelevant features."""

# separating the features after regularization
X = diabetes_dataset.drop(columns = ['Outcome','SkinThickness'], axis=1)
Y = diabetes_dataset['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)
# Standardize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Training the Model

# Logistic Regression

# Hyperparameter Tuning
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# Define the parameter grid for Grid Search
param_grid = {
    'C': [0.1, 1, 10, 100],
    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],
    'penalty': ['l2'],  # 'l1' penalty requires a solver that supports it (liblinear, saga)
    'max_iter': [100, 200, 300]
}

# Initialize the Logistic Regression classifier
log_reg = LogisticRegression()

# Initialize GridSearchCV
grid_search_log_reg = GridSearchCV(estimator=log_reg, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)

# Fit the grid search to the training data
grid_search_log_reg.fit(X_train_scaled, y_train)

# Print the best parameters and best score
print("Best parameters found: ", grid_search_log_reg.best_params_)
print("Best accuracy score: ", grid_search_log_reg.best_score_)

# Get the best estimator from the grid search
best_log_reg = grid_search_log_reg.best_estimator_

# Evaluate the best model on the test set
y_pred_log_reg = best_log_reg.predict(X_test_scaled)

accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
precision_log_reg = precision_score(y_test, y_pred_log_reg)
recall_log_reg = recall_score(y_test, y_pred_log_reg)
f1_log_reg = f1_score(y_test, y_pred_log_reg)

print("Test set evaluation metrics for Logistic Regression:")
print("Accuracy: ", accuracy_log_reg)
print("Precision: ", precision_log_reg)
print("Recall: ", recall_log_reg)
print("F1 Score: ", f1_log_reg)

from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import accuracy_score, recall_score,f1_score,precision_score,confusion_matrix
from sklearn.model_selection import train_test_split

# 5- Model fitting
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(C= 10, max_iter= 100, penalty= 'l2', solver= 'newton-cg')
lr.fit(X_train_scaled,y_train)
Y_pred_lr = lr.predict(X_test_scaled)

Y_pred_lr.shape
score_lr = round(accuracy_score(Y_pred_lr,y_test)*100,2)
print("The accuracy score achieved using Logistic Regression is: "+str(score_lr))

"""# Trying with different parameters"""

lr = LogisticRegression(C= 50, max_iter= 200, penalty= 'l2', solver= 'saga')
lr.fit(X_train_scaled,y_train)
Y_pred_lr = lr.predict(X_test_scaled)

Y_pred_lr.shape
score_lr = round(accuracy_score(Y_pred_lr,y_test)*100,2)
print("The accuracy score achieved using Logistic Regression is: "+str(score_lr))

lr = LogisticRegression(C= 100, max_iter= 100, penalty= 'l2', solver= 'liblinear')
lr.fit(X_train_scaled,y_train)
Y_pred_lr = lr.predict(X_test_scaled)

Y_pred_lr.shape
score_lr = round(accuracy_score(Y_pred_lr,y_test)*100,2)
print("The accuracy score achieved using Logistic Regression is: "+str(score_lr))

#Confusion matrix and classification report
print(confusion_matrix(Y_pred_lr,y_test))
print(classification_report(y_test,Y_pred_lr))

"""# Support Vector Machine(SVM)

# Hyperparameter Tuning
"""

# Define the parameter grid for Grid Search
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [1, 0.1, 0.01],
    'kernel': ['linear', 'rbf']
}

# Initialize the SVM classifier
svm = SVC()

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1)

# Fit the grid search to the training data
grid_search.fit(X_train_scaled, y_train)

# Print the best parameters and best score
print("Best parameters found: ", grid_search.best_params_)
print("Best accuracy score: ", grid_search.best_score_)

# Evaluate the best model on the test set
best_svm = grid_search.best_estimator_
y_pred_svm = best_svm.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred_svm)
precision = precision_score(y_test, y_pred_svm)
recall = recall_score(y_test, y_pred_svm)
f1 = f1_score(y_test, y_pred_svm)

print("Test set evaluation metrics:")
print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)

classifier = SVC(kernel='rbf',C=100,gamma=0.001)

#training the support vector Machine Classifier
classifier.fit(X_train_scaled, y_train)

"""# Model Evaluation

Accuracy Score
"""

# accuracy score on the training data
X_train_prediction = classifier.predict(X_train_scaled)
training_data_accuracy = accuracy_score(X_train_prediction, y_train)

print('Accuracy score of the training data : ', training_data_accuracy)

# accuracy score on the test data
X_test_prediction = classifier.predict(X_test_scaled)
test_data_accuracy = accuracy_score(X_test_prediction, y_test)

print('Accuracy score of the test data : ', test_data_accuracy)

"""# Trying with different Parameters"""

classifier = SVC(kernel='rbf',C=50,gamma=0.01)
#training the support vector Machine Classifier
classifier.fit(X_train_scaled, y_train)
# accuracy score on the test data
X_test_prediction = classifier.predict(X_test_scaled)
test_data_accuracy = accuracy_score(X_test_prediction, y_test)
print('Accuracy score of the test data : ', test_data_accuracy)

classifier = SVC(kernel='poly',C=100,gamma=0.01)
#training the support vector Machine Classifier
classifier.fit(X_train_scaled, y_train)
# accuracy score on the test data
X_test_prediction = classifier.predict(X_test_scaled)
test_data_accuracy = accuracy_score(X_test_prediction, y_test)
print('Accuracy score of the test data : ', test_data_accuracy)

classifier = SVC(kernel='linear',C=10,gamma=1)
#training the support vector Machine Classifier
classifier.fit(X_train_scaled, y_train)
# accuracy score on the test data
X_test_prediction = classifier.predict(X_test_scaled)
test_data_accuracy = accuracy_score(X_test_prediction, y_test)
print('Accuracy score of the test data : ', test_data_accuracy)

"""# KNearestNeighbour

# Hyperparameter Optimization
"""

from sklearn.neighbors import KNeighborsClassifier

# Define the parameter grid for Grid Search
param_grid = {
    'n_neighbors': np.arange(1, 31, 2),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

# Initialize the KNN classifier
knn = KNeighborsClassifier()

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)

# Fit the grid search to the training data
grid_search.fit(X_train_scaled, y_train)

# Print the best parameters and best score
print("Best parameters found: ", grid_search.best_params_)
print("Best accuracy score: ", grid_search.best_score_)

# Evaluate the best model on the test set
best_knn = grid_search.best_estimator_
y_pred_knn = best_knn.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred_knn)
precision = precision_score(y_test, y_pred_knn)
recall = recall_score(y_test, y_pred_knn)
f1 = f1_score(y_test, y_pred_knn)

print("Test set evaluation metrics:")
print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)

"""# Model Training using KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric= 'manhattan', n_neighbors= 19, weights= 'distance')
knn.fit(X_train_scaled,y_train)
Y_pred_knn = knn.predict(X_test_scaled)

Y_pred_knn.shape

score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)
print("The accuracy achieved using KNN is: "+str(score_knn)+"%")

"""# Trying with Different Hyperparameters"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 15, weights= 'distance')
knn.fit(X_train_scaled,y_train)
Y_pred_knn = knn.predict(X_test_scaled)
Y_pred_knn.shape
score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)
print("The accuracy achieved using KNN is: "+str(score_knn)+"%")

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 25, weights= 'uniform')
knn.fit(X_train_scaled,y_train)
Y_pred_knn = knn.predict(X_test_scaled)
Y_pred_knn.shape
score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)
print("The accuracy achieved using KNN is: "+str(score_knn)+"%")

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric= 'minkowski', n_neighbors= 19, weights= 'distance')
knn.fit(X_train_scaled,y_train)
Y_pred_knn = knn.predict(X_test_scaled)
Y_pred_knn.shape
score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)
print("The accuracy achieved using KNN is: "+str(score_knn)+"%")

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(metric= 'minkowski', n_neighbors= 19, weights= 'uniform')
knn.fit(X_train_scaled,y_train)
Y_pred_knn = knn.predict(X_test_scaled)
Y_pred_knn.shape
score_knn = round(accuracy_score(Y_pred_knn,y_test)*100,2)
print("The accuracy achieved using KNN is: "+str(score_knn)+"%")

"""# Neural Network"""

# separating the features after regularization
X = diabetes_dataset.drop(columns = ['Outcome'], axis=1)
Y = diabetes_dataset['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, stratify=Y, random_state=2)

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

max_accuracy = 0
best_params = None

# Define parameters to search over
hidden_layer_sizes_options = [(10,), (20,), (30,), (40,), (50,)]
activation_options = ['relu', 'tanh']
solver_options = ['adam', 'sgd']
max_iter_options = [200, 300, 400, 500, 600]

for hidden_layer_sizes in hidden_layer_sizes_options:
    for activation in activation_options:
        for solver in solver_options:
            for max_iter in max_iter_options:
                mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, max_iter=max_iter, random_state=0)
                mlp.fit(X_train, y_train)
                Y_pred_mlp = mlp.predict(X_test)
                current_accuracy = round(accuracy_score(y_test, Y_pred_mlp), 2)
                if current_accuracy > max_accuracy:
                    max_accuracy = current_accuracy
                    best_params = (hidden_layer_sizes, activation, solver, max_iter)

print("Best parameters found:", best_params)
print("Best accuracy found:", max_accuracy)

# Train MLPClassifier with best parameters found
mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=200, random_state=0)
mlp.fit(X_train, y_train)
Y_pred_mlp = mlp.predict(X_test)

mlp_accuracy = accuracy_score(y_test, Y_pred_mlp)
print("Accuracy of MLPClassifier:", mlp_accuracy)

"""# HyperParameter Optimization"""

# Train MLPClassifier with best parameters found
mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='sgd', max_iter=300, random_state=0)
mlp.fit(X_train, y_train)
Y_pred_mlp = mlp.predict(X_test)

mlp_accuracy = accuracy_score(y_test, Y_pred_mlp)
print("Accuracy of MLPClassifier:", mlp_accuracy)

# Train MLPClassifier with best parameters found
mlp = MLPClassifier(hidden_layer_sizes=(30,), activation='tanh', solver='adam', max_iter=200, random_state=0)
mlp.fit(X_train, y_train)
Y_pred_mlp = mlp.predict(X_test)

mlp_accuracy = accuracy_score(y_test, Y_pred_mlp)
print("Accuracy of MLPClassifier:", mlp_accuracy)

# Train MLPClassifier with best parameters found
mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=200, random_state=0)
mlp.fit(X_train, y_train)
Y_pred_mlp = mlp.predict(X_test)

mlp_accuracy = accuracy_score(y_test, Y_pred_mlp)
print("Accuracy of MLPClassifier:", mlp_accuracy)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the models
models = {
    'SVM': SVC(kernel='linear',C=10,gamma=1),
    'Logistic Regression': LogisticRegression(C= 10, max_iter= 100, penalty= 'l2', solver= 'newton-cg'),
    'KNN': KNeighborsClassifier(metric= 'minkowski', n_neighbors= 19, weights= 'distance'),
    'Neural Network': MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=200, random_state=0)
}

# Train and evaluate the models
results = []
for model_name, model in models.items():
    # Train the model
    model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = model.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Store the results
    results.append({
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    })

# Convert results to a DataFrame
results_df = pd.DataFrame(results)

# Display the results
print(results_df)

# Plot the results
results_df.set_index('Model').plot(kind='bar', figsize=(10, 6))
plt.title('Model Comparison on Diabetes Dataset')
plt.ylabel('Score')
plt.xticks(rotation=45)
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.show()

"""# Making a Predictive System"""

input_data = (4,110,92,0,0,37.6,0.191,30)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = mlp.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

"""# Saving the trained model"""

import pickle

filename = 'diabetes_model.sav'
pickle.dump(mlp, open(filename, 'wb'))

# loading the saved model
loaded_model = pickle.load(open('diabetes_model.sav', 'rb'))

input_data = (4,110,92,0,0,37.6,0.191,30)

# changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the array as we are predicting for one instance
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

prediction = loaded_model.predict(input_data_reshaped)
print(prediction)

if (prediction[0] == 0):
  print('The person is not diabetic')
else:
  print('The person is diabetic')

for column in X.columns:
  print(column)